{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATE_TEMPLATE = re.compile(r'\\d{2}\\.\\d{2}\\.\\d{4}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank line found >  \n",
      "blank line found >  \n"
     ]
    }
   ],
   "source": [
    "def preprocess_input():\n",
    "    date_string = \"\"\n",
    "\n",
    "    f = open(\"manual_input.txt\", \"r\", encoding=\"utf8\")\n",
    "    preprocessed_input = open(\"preprocessed_input.txt\", \"w\", encoding=\"utf8\")\n",
    "    ff = f.read().splitlines()\n",
    "\n",
    "    for i in ff:\n",
    "        if re.match(DATE_TEMPLATE, i) is not None:\n",
    "            date_string = i\n",
    "        else:\n",
    "            if i:\n",
    "                preprocessed_input.write(date_string + \" \" + i + \"\\n\")\n",
    "            else:\n",
    "                print(\"blank line found > \", i)\n",
    "    f.close()\n",
    "    preprocessed_input.close()\n",
    "\n",
    "preprocess_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'89140580517 хочет купить ноутбук за 17000 руб ездить Якутия.'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = ET.parse('output.xml')\n",
    "root = tree.getroot()\n",
    "r = root.findall(\"Lead\")\n",
    "\n",
    "def make_dict_of_leads(root=root):\n",
    "    dict_of_leads = dict();\n",
    "    for lead in root.iter('Lead'):\n",
    "        id = lead.attrib[\"id\"]\n",
    "\n",
    "        pulpy = ET.fromstring(lead.attrib[\"text\"])\n",
    "        source_sentence = pulpy.find(\"b\").find(\"s\")\n",
    "\n",
    "        remove_explicit_from_sentence(source_sentence)\n",
    "\n",
    "        text = ''.join(source_sentence.itertext())\n",
    "        dict_of_leads[id] = text;\n",
    "#         dict_of_leads[id] = source_sentence\n",
    "    return dict_of_leads\n",
    "\n",
    "def remove_explicit_from_sentence(xml_sentence):\n",
    "    # to remove\n",
    "    phoneno = re.compile(r'\\d{11}')\n",
    "    date = DATE_TEMPLATE\n",
    "\n",
    "    for i in xml_sentence:\n",
    "        if re.match(phoneno, i.attrib[\"lemma\"]):\n",
    "            xml_sentence.remove(i)\n",
    "        if re.match(date, i.attrib[\"lemma\"]):\n",
    "            xml_sentence.remove(i)\n",
    "    \n",
    "\n",
    "make_dict_of_leads()[\"46\"]\n",
    "\n",
    "one = make_dict_of_leads()['0']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "   <b>\n",
    "      <s>\n",
    "         21.06.2016\n",
    "         <P n0=\"\" lemma=\"89140580517\">89140580517</P>\n",
    "         хочет\n",
    "         <W n1=\"\" lemma=\"buy\">купить</W>\n",
    "         <W n2=\"\" lemma=\"ноутбук\">ноутбук</W>\n",
    "         за 17000 руб ездить\n",
    "         <P n3=\"\" lemma=\"Якутия\">Якутия</P>\n",
    "         .\n",
    "      </s>\n",
    "   </b>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# todo: помнить о тексте лида. Там выделены факты прямо в разметке - полезно при выводе информации в веб-интерфейсе\n",
    "\n",
    "def compare_facts_to_leads(root=root):\n",
    "    facts_grouped_by_lead = dict()\n",
    "\n",
    "    for i in root.find(\"document\").find('facts'):\n",
    "        lead_id = i.attrib['LeadID']\n",
    "        if facts_grouped_by_lead.get(lead_id):\n",
    "            facts_grouped_by_lead[lead_id].append(i)\n",
    "        else:\n",
    "            facts_grouped_by_lead[lead_id] = [i]\n",
    "    return facts_grouped_by_lead\n",
    "\n",
    "def make_common_table():    \n",
    "    appendix = [\n",
    "        \"date\",\n",
    "        \"conversation\",\n",
    "        \"source_sentence\"\n",
    "    ]\n",
    "    calls = df()\n",
    "    \n",
    "    facts = compare_facts_to_leads()\n",
    "    leads = make_dict_of_leads()\n",
    "\n",
    "    for lead in facts:\n",
    "        try:\n",
    "            elems = facts[lead]\n",
    "            one_sentence = lead\n",
    "            cols = []\n",
    "            values = []\n",
    "            for fact_name in elems:\n",
    "                for fact_field in fact_name:\n",
    "    #                 print(fact_name.tag, fact_field.tag)\n",
    "    #                 print(fact_field.attrib[\"val\"])\n",
    "    #                 print()\n",
    "\n",
    "                    cols.append(fact_name.tag + \"_\" + fact_field.tag)\n",
    "                    values.append(fact_field.attrib[\"val\"])\n",
    "            one_row = pd.DataFrame([values], columns=cols)\n",
    "            calls = calls.append(one_row)\n",
    "\n",
    "            values = []\n",
    "            cols = []\n",
    "        except ValueError:\n",
    "            print(lead)\n",
    "            print(leads[lead])\n",
    "            pass\n",
    "    return calls;\n",
    "\n",
    "calls = make_common_table()\n",
    "\n",
    "\n",
    "to_str = lambda x: \" \" + x if x is not np.nan else \"\"\n",
    "calls[\"notebook\"] = calls[\"Notebook_Word\"] + calls[\"Notebook_Vendor\"].map(to_str)\n",
    "calls[\"phone\"] = calls[\"Phone_Word\"] + calls[\"Phone_Vendor\"].map(to_str) + calls[\"Phone_Model\"].map(to_str)\n",
    "\n",
    "calls.drop(['Notebook_Word', 'Notebook_Vendor'], axis=1, inplace=True)\n",
    "calls.drop(['Phone_Word', 'Phone_Vendor', 'Phone_Model'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "pawn = calls[calls.Pawn_Word.notnull()]\n",
    "buy_out = calls[calls.CustomerBuys_Word.notnull()]\n",
    "buy_out.to_excel(\"buy_out.xlsx\")\n",
    "pawn.to_excel(\"pawn.xlsx\")\n",
    "\n",
    "calls.to_excel(\"whole_table.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
